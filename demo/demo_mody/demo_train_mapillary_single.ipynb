{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-14T07:33:45.315874Z",
     "start_time": "2018-03-14T07:33:43.991489Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF :  1.6.0   Keras :  2.1.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "## STANDARD PYTHON LIBS\n",
    "import os\n",
    "import re\n",
    "import sys\n",
    "import cv2\n",
    "import PIL\n",
    "import math\n",
    "import time\n",
    "import random\n",
    "import scipy.misc\n",
    "import skimage.io\n",
    "import skimage.transform\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "## ADDING TO ROOT\n",
    "ROOT_DIR = os.path.abspath(os.path.join(os.getcwd(), '../'))\n",
    "sys.path.append(ROOT_DIR)\n",
    "\n",
    "## CUSTOM LIBS\n",
    "from src.model import log\n",
    "import src.utils as utils\n",
    "import src.model as modellib\n",
    "from src.config import Config\n",
    "import src.visualize as visualize\n",
    "\n",
    "# GPU LIBS\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "\n",
    "print ('TF : ', tf.__version__, '  Keras : ', keras.__version__)\n",
    "\n",
    "# if utils.check_gpu(verbose=0):\n",
    "#     pass\n",
    "# else:\n",
    "#     sys.exit(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CUSTOMIZATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-13T06:42:40.553875Z",
     "start_time": "2018-03-13T06:42:40.531466Z"
    },
    "code_folding": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[128, 128],\n",
       "       [ 64,  64],\n",
       "       [ 32,  32],\n",
       "       [ 16,  16],\n",
       "       [  8,   8]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class MapillaryConfig(Config):\n",
    "    NAME = \"mapillary\"\n",
    "\n",
    "    GPU_COUNT = 1\n",
    "    IMAGES_PER_GPU = 1\n",
    "    \n",
    "    NUM_CLASSES = 1 + 14  # background + 3 shapes\n",
    "    # [ '1' '17' '23' '24' '25' '26' '27' '28' '29' '30' '31' '32' '33' '8']\n",
    "    \n",
    "    IMAGE_MAX_DIM = 512\n",
    "    \n",
    "    USE_MINI_MASK = True\n",
    "    MINI_MASK_SHAPE = (56, 56)  # (height, width) of the mini-mask\n",
    "\n",
    "    RPN_ANCHOR_SCALES = (32, 64, 128, 256, 512)  # anchor side in pixels\n",
    "    RPN_ANCHOR_RATIOS = [0.5, 1, 2]\n",
    "    \n",
    "    TRAIN_ROIS_PER_IMAGE = 50\n",
    "    ROI_POSITIVE_RATIO = 0.9\n",
    "    \n",
    "    STEPS_PER_EPOCH = 10\n",
    "    VALIDATION_STEPS = 2\n",
    "    \n",
    "config = MapillaryConfig()\n",
    "config.BACKBONE_SHAPES\n",
    "# config.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-13T06:42:40.825586Z",
     "start_time": "2018-03-13T06:42:40.556037Z"
    },
    "code_folding": [
     20,
     25,
     31,
     54
    ]
   },
   "outputs": [],
   "source": [
    "class MapillaryDataset(utils.Dataset):\n",
    "    \n",
    "    def add_classes(self):\n",
    "        self.dataset = 'mapillary'\n",
    "        # self.add_class(self.dataset, 0, \"unlabelled\")\n",
    "        self.add_class(self.dataset, 1, \"void-ego vehicle\")\n",
    "        self.add_class(self.dataset, 8, \"flat-sidewalk\")\n",
    "        self.add_class(self.dataset, 17, \"object-pole\")\n",
    "        self.add_class(self.dataset, 23, \"sky-sky\")\n",
    "        self.add_class(self.dataset, 24, \"human-person\")\n",
    "        self.add_class(self.dataset, 25, \"human-rider\")\n",
    "        self.add_class(self.dataset, 26, \"vehicle-car\")\n",
    "        self.add_class(self.dataset, 27, \"vehicle-truck\")\n",
    "        self.add_class(self.dataset, 28, \"vehicle-bus\")\n",
    "        self.add_class(self.dataset, 29, \"vehicle-caravan\")\n",
    "        self.add_class(self.dataset, 30, \"vehicle-trailer\")\n",
    "        self.add_class(self.dataset, 31, \"vehicle-train\")\n",
    "        self.add_class(self.dataset, 32, \"vehicle-motorcycle\")\n",
    "        self.add_class(self.dataset, 33, \"vehicle-bicycle\")\n",
    "    \n",
    "    def add_image_mapillary(self, image_id, image_folder_path, image_file_name):\n",
    "        image_path = os.path.join(image_folder_path, image_file_name)\n",
    "        self.add_image(self.dataset, image_id=image_id, path=None\n",
    "                       , image_folder_path = image_folder_path, image_file_name = image_file_name)\n",
    "    \n",
    "    def load_image(self, image_id):\n",
    "        image_folder_path = self.image_info[image_id]['image_folder_path']\n",
    "        image_file_name   = self.image_info[image_id]['image_file_name']\n",
    "        img = skimage.io.imread(os.path.join(image_folder_path, image_file_name))\n",
    "        return self.helper_img_shrink(img)\n",
    "    \n",
    "    def load_mask(self, image_id):\n",
    "        image_folder_path = self.image_info[image_id]['image_folder_path']\n",
    "        image_file_name   = self.image_info[image_id]['image_file_name']\n",
    "        mask_file_name    = image_file_name.split('.jpg')[0] + '.npz'\n",
    "        mask_file_path    = os.path.join(image_folder_path, mask_file_name)\n",
    "        \n",
    "        \n",
    "        masks_res_tmp     = []\n",
    "        class_ids_res     = []\n",
    "        masks_sparse = np.load(mask_file_path)\n",
    "        for class_id in masks_sparse:\n",
    "            for instance_id in masks_sparse[class_id].item():\n",
    "                mask_class_instance = np.array(masks_sparse[class_id].item()[instance_id].todense())\n",
    "                masks_res_tmp.append(self.helper_img_shrink(mask_class_instance))\n",
    "                class_ids_res.append(class_id)\n",
    "        \n",
    "        h, w = masks_res_tmp[0].shape\n",
    "        masks_res = np.zeros([h, w, len(masks_res_tmp)], dtype=np.uint8)\n",
    "        for i, mask in enumerate(masks_res_tmp):\n",
    "            masks_res[:, :, i] = mask\n",
    "                \n",
    "        return np.array(masks_res), np.array(class_ids_res).astype(np.uint32)\n",
    "    \n",
    "    def helper_img_shrink(self, img, MAX_DIM=512, show=0, verbose=0):\n",
    "        if verbose : print ('-->', img.shape, list(np.unique(img)))\n",
    "        if len(img.shape) == 3      : (h,w,d) = img.shape\n",
    "        elif len(img.shape) == 2    : (h,w)   = img.shape\n",
    "        img_aspect = max(h,w) / min(h,w)\n",
    "        MIN_DIM = MAX_DIM / img_aspect\n",
    "        img_trans = skimage.transform.resize(img, (MIN_DIM, MAX_DIM), preserve_range=True, mode='reflect')\n",
    "        img_trans = np.array(img_trans, dtype = np.uint8)\n",
    "        if verbose : print ('-------->', img_trans.shape, list(np.unique(img_trans)))\n",
    "\n",
    "        if show:\n",
    "            f,axarr = plt.subplots(1,2, figsize=(15,15))\n",
    "            axarr[0].imshow(img)\n",
    "            axarr[1].imshow(img_trans)\n",
    "        return img_trans\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    trainData = MapillaryDataset()\n",
    "    trainData.add_classes()\n",
    "    trainData.add_image_mapillary(0, './raw/data', '_1AbvbARvB-5S0rAPN02Mg.jpg')\n",
    "    trainData.prepare()\n",
    "    \n",
    "    valData = MapillaryDataset()\n",
    "    valData.add_classes()\n",
    "    valData.add_image_mapillary(0, './raw/data', '_2g1p_iHAUNc2KTgESz5KA.jpg')\n",
    "    valData.prepare()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-13T06:42:47.194647Z",
     "start_time": "2018-03-13T06:42:40.828325Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(384, 512, 3) (384, 512, 16) (16,)\n",
      "--> Classes :  [ 8 17 23 24 26 27 28 32]\n",
      "Total Size :  3.56256103515625  MB\n"
     ]
    }
   ],
   "source": [
    "img = trainData.load_image(0)\n",
    "masks, class_ids = trainData.load_mask(0)\n",
    "print (img.shape, masks.shape, class_ids.shape)\n",
    "print ('--> Classes : ', np.unique(class_ids))\n",
    "print ('Total Size : ', (img.nbytes + masks.nbytes + class_ids.nbytes)/1024.0/1024.0, ' MB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-13T06:48:17.546207Z",
     "start_time": "2018-03-13T06:48:17.539783Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainData.class_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-13T06:42:49.709201Z",
     "start_time": "2018-03-13T06:42:47.197987Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(384, 512, 3) (384, 512, 9) (9,)\n",
      "--> Classes :  [ 8 17 23 26 27 28]\n",
      "Total Size :  2.2500343322753906  MB\n"
     ]
    }
   ],
   "source": [
    "img = valData.load_image(0)\n",
    "masks, class_ids = valData.load_mask(0)\n",
    "print (img.shape, masks.shape, class_ids.shape)\n",
    "print ('--> Classes : ', np.unique(class_ids))\n",
    "print ('Total Size : ', (img.nbytes + masks.nbytes + class_ids.nbytes)/1024.0/1024.0, ' MB')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TRAINING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-13T06:42:59.347372Z",
     "start_time": "2018-03-13T06:42:49.711637Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------> input_gt_class_ids : Tensor(\"input_gt_class_ids:0\", shape=(?, ?), dtype=int32)\n",
      "\n",
      "--------------------------\n",
      "[play] rois : (1, ?, ?)\n",
      "[play] target_class_ids : (1, ?)\n",
      "[play] target_bbox : Tensor(\"proposal_targets/target_bbox:0\", shape=(1, ?, ?), dtype=float32)\n",
      "[play] target_mask : Tensor(\"proposal_targets/target_mask:0\", shape=(1, ?, ?, ?), dtype=float32)\n",
      "mrcnn_mask : Tensor(\"mrcnn_mask/Reshape_1:0\", shape=(?, 50, 28, 28, 15), dtype=float32)\n",
      "[play][mrcnn_class_loss_graph] target_class_ids  : Tensor(\"proposal_targets/target_class_ids:0\", shape=(1, ?), dtype=int32)\n",
      "[play][mrcnn_class_loss_graph] pred_class_logits : Tensor(\"mrcnn_class_logits/Reshape_1:0\", shape=(?, 50, 15), dtype=float32)\n",
      "[play][mrcnn_class_loss_graph] active_class_ids  : Tensor(\"lambda_4/strided_slice_3:0\", shape=(?, ?), dtype=float32)\n",
      "[play][mrcnn_class_loss_graph] target_class_ids  : Tensor(\"mrcnn_class_loss/Placeholder:0\", shape=(?, 1), dtype=float32)\n",
      "[play][mrcnn_class_loss_graph] pred_class_logits : Tensor(\"mrcnn_class_loss/Placeholder_1:0\", shape=(?, 50, 15), dtype=float32)\n",
      "[play][mrcnn_class_loss_graph] active_class_ids  : Tensor(\"mrcnn_class_loss/Placeholder_2:0\", shape=(?, ?), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "MODEL_DIR = os.path.join(ROOT_DIR, \"logs\")\n",
    "COCO_MODEL_PATH = os.path.join(ROOT_DIR, 'demo', 'model', \"mask_rcnn_coco.h5\")\n",
    "model = modellib.MaskRCNN(mode=\"training\", config=config, model_dir=MODEL_DIR)\n",
    "\n",
    "init_with = \"coco\"  # imagenet, coco, or last\n",
    "\n",
    "if init_with == \"imagenet\":\n",
    "    model.load_weights(model.get_imagenet_weights(), by_name=True)\n",
    "elif init_with == \"coco\":\n",
    "    model.load_weights(COCO_MODEL_PATH, by_name=True,\n",
    "                       exclude=[\"mrcnn_class_logits\", \"mrcnn_bbox_fc\", \n",
    "                                \"mrcnn_bbox\", \"mrcnn_mask\"])\n",
    "elif init_with == \"last\":\n",
    "    model.load_weights(model.find_last()[1], by_name=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-13T06:44:21.053827Z",
     "start_time": "2018-03-13T06:42:59.349548Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting at epoch 0. LR=0.001\n",
      "\n",
      "Checkpoint Path: /home/play/playment/production/Mask_RCNN/logs/mapillary20180313T0642/mask_rcnn_mapillary_{epoch:04d}.h5\n",
      "Selecting layers to train\n",
      "fpn_c5p5               (Conv2D)\n",
      "fpn_c4p4               (Conv2D)\n",
      "fpn_c3p3               (Conv2D)\n",
      "fpn_c2p2               (Conv2D)\n",
      "fpn_p5                 (Conv2D)\n",
      "fpn_p2                 (Conv2D)\n",
      "fpn_p3                 (Conv2D)\n",
      "fpn_p4                 (Conv2D)\n",
      "In model:  rpn_model\n",
      "    rpn_conv_shared        (Conv2D)\n",
      "    rpn_class_raw          (Conv2D)\n",
      "    rpn_bbox_pred          (Conv2D)\n",
      "mrcnn_mask_conv1       (TimeDistributed)\n",
      "mrcnn_mask_bn1         (TimeDistributed)\n",
      "mrcnn_mask_conv2       (TimeDistributed)\n",
      "mrcnn_mask_bn2         (TimeDistributed)\n",
      "mrcnn_class_conv1      (TimeDistributed)\n",
      "mrcnn_class_bn1        (TimeDistributed)\n",
      "mrcnn_mask_conv3       (TimeDistributed)\n",
      "mrcnn_mask_bn3         (TimeDistributed)\n",
      "mrcnn_class_conv2      (TimeDistributed)\n",
      "mrcnn_class_bn2        (TimeDistributed)\n",
      "mrcnn_mask_conv4       (TimeDistributed)\n",
      "mrcnn_mask_bn4         (TimeDistributed)\n",
      "mrcnn_bbox_fc          (TimeDistributed)\n",
      "mrcnn_mask_deconv      (TimeDistributed)\n",
      "mrcnn_class_logits     (TimeDistributed)\n",
      "mrcnn_mask             (TimeDistributed)\n",
      "WARNING:tensorflow:From /home/play/playment/production/Mask_RCNN/src/model.py:2117: calling reduce_mean (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/gradients_impl.py:98: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/usr/local/lib/python3.5/dist-packages/keras/engine/training.py:2095: UserWarning: Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the`keras.utils.Sequence class.\n",
      "  UserWarning('Using a generator with `use_multiprocessing=True`'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "10/10 [==============================] - 35s 3s/step - loss: nan - rpn_class_loss: 0.6486 - rpn_bbox_loss: 0.6789 - mrcnn_class_loss: nan - mrcnn_bbox_loss: 0.0630 - mrcnn_mask_loss: 0.7720 - val_loss: nan - val_rpn_class_loss: 0.7052 - val_rpn_bbox_loss: 0.4630 - val_mrcnn_class_loss: nan - val_mrcnn_bbox_loss: 0.0000e+00 - val_mrcnn_mask_loss: 0.0000e+00\n",
      "Epoch 2/2\n",
      "10/10 [==============================] - 12s 1s/step - loss: nan - rpn_class_loss: 0.7036 - rpn_bbox_loss: 0.6967 - mrcnn_class_loss: nan - mrcnn_bbox_loss: 0.0000e+00 - mrcnn_mask_loss: 0.0000e+00 - val_loss: nan - val_rpn_class_loss: 0.7052 - val_rpn_bbox_loss: 0.4630 - val_mrcnn_class_loss: nan - val_mrcnn_bbox_loss: 0.0000e+00 - val_mrcnn_mask_loss: 0.0000e+00\n"
     ]
    }
   ],
   "source": [
    "model.train(trainData, valData, \n",
    "            learning_rate=config.LEARNING_RATE, \n",
    "            epochs=2, \n",
    "            layers='heads')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# INFERENCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-13T06:44:21.060689Z",
     "start_time": "2018-03-13T06:44:21.056020Z"
    }
   },
   "outputs": [],
   "source": [
    "# class InferenceConfig(MapillaryConfig):\n",
    "#     GPU_COUNT = 1\n",
    "#     IMAGES_PER_GPU = 1\n",
    "\n",
    "# inference_config = InferenceConfig()\n",
    "# model = modellib.MaskRCNN(mode=\"inference\", config=inference_config, model_dir=MODEL_DIR)\n",
    "# model_path = model.find_last()[1]\n",
    "\n",
    "# if model_path != None:\n",
    "#     model.load_weights(model_path, by_name=True)\n",
    "# else:\n",
    "#     print (model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-13T06:44:21.111508Z",
     "start_time": "2018-03-13T06:44:21.062399Z"
    }
   },
   "outputs": [],
   "source": [
    "# def get_ax(rows=1, cols=1, size=8):\n",
    "#     _, ax = plt.subplots(rows, cols, figsize=(size*cols, size*rows))\n",
    "#     return ax\n",
    "\n",
    "# test_img = trainData.load_image(0)\n",
    "# results  = model.detect([test_img], verbose=1)\n",
    "# r = results[0]\n",
    "# visualize.display_instances(test_img, r['rois'], r['masks'], r['class_ids'], \n",
    "#                             valData.class_names, r['scores'], ax=get_ax())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-13T06:44:21.153273Z",
     "start_time": "2018-03-13T06:44:21.113729Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'r' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-3740ee0a989c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'rois'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'r' is not defined"
     ]
    }
   ],
   "source": [
    "r['rois']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SCRATCHPAD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-13T06:44:21.154183Z",
     "start_time": "2018-03-13T06:42:39.056Z"
    }
   },
   "outputs": [],
   "source": [
    "a = ([1,2,3,4], [1,1])\n",
    "# zip(*a))\n",
    "list(zip(*a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-09T09:32:01.814540Z",
     "start_time": "2018-03-09T09:32:01.802910Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
